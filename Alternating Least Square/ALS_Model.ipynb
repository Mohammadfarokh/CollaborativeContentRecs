{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking system version and used packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System version: 3.11.10 | packaged by conda-forge | (main, Oct 16 2024, 01:27:36) [GCC 13.3.0]\n",
      "Pandas version: 2.2.3\n",
      "PySpark version: 3.5.4\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import FloatType, IntegerType, LongType\n",
    "\n",
    "from spark.starter import start_spark\n",
    "from validation.spark_validation import SparkValidation\n",
    "from data.data_helper import data_split\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "print(f\"System version: {sys.version}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"PySpark version: {pyspark.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data structure and used parameters for the ALS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Data structure\n",
    "COL_CUS = \"customer_id\"\n",
    "COL_GAME = \"game_id\"\n",
    "COL_RATING = \"rating\"\n",
    "COL_PREDICTION = \"prediction\"\n",
    "COL_TIMESTAMP = \"timestamp\"\n",
    "schema = StructType(\n",
    "    (\n",
    "        StructField(COL_CUS, IntegerType()),\n",
    "        StructField(COL_GAME, IntegerType()),\n",
    "        StructField(COL_RATING, FloatType()),\n",
    "        StructField(COL_TIMESTAMP, LongType()),\n",
    "    )\n",
    ")\n",
    "# Model parameters\n",
    "RANK = 10\n",
    "MAX_ITER = 15\n",
    "REG_PARAM = 0.05\n",
    "K = 10 # number of recommendations for the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/20 07:44:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = start_spark(\"ALS Deep Dive\", memory=\"16g\")\n",
    "spark.conf.set(\"spark.sql.analyzer.failAmbiguousSelfJoin\", \"false\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading data from csv into a Spark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/19 14:03:34 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------------+----------+\n",
      "|customer_id|game_id|      rating| timestamp|\n",
      "+-----------+-------+------------+----------+\n",
      "|    8561354|    201| 0.020287959|1685009284|\n",
      "|    8561354|    201| 0.020287959|1685009285|\n",
      "|    8561354|    201| 0.020287959|1685009286|\n",
      "|    8561354|    201| 0.020287959|1685009286|\n",
      "|    8561354|    201| 0.020287959|1685009287|\n",
      "|    8561354|    201| 0.020287959|1685009287|\n",
      "|    8561354|    401|0.0019633507|1685009289|\n",
      "|    8561354|    402|0.0019633507|1685009290|\n",
      "|    8561354|    401|0.0019633507|1685009290|\n",
      "|    8561354|    402|0.0019633507|1685009291|\n",
      "|    8577554|1000001|  0.30104712|1685009981|\n",
      "|    8577554|1000001|  0.30104712|1685009981|\n",
      "|    8577554|1000000| 0.009816754|1685009982|\n",
      "|    8577554|1000002|         1.0|1685009982|\n",
      "|    8577554|1000002|         1.0|1685009982|\n",
      "|    8577554|1000002|         1.0|1685009982|\n",
      "|    8577554|1000002|         1.0|1685009983|\n",
      "|    8577554|1000002|         1.0|1685009983|\n",
      "|    8577554|1000002|         1.0|1685009983|\n",
      "|    8577554|1000002|         1.0|1685009983|\n",
      "+-----------+-------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"Load ALS Data\").getOrCreate()\n",
    "\n",
    "# Path to the CSV file \n",
    "file_path = \"/root/Recommendation_system.csv\"\n",
    "\n",
    "# Load the CSV into a Spark DataFrame\n",
    "dfs = spark.read.csv(file_path, schema=schema, header=True)\n",
    "\n",
    "# Show the data\n",
    "dfs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the Data by 75-25 ratio for training and testing of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_train, dfs_test = data_split(dfs, ratio=0.75, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the movielens model using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/19 08:51:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "25/02/19 08:51:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "25/02/19 08:51:21 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "als = ALS(\n",
    "    maxIter=MAX_ITER, \n",
    "    rank=RANK,\n",
    "    regParam=REG_PARAM, \n",
    "    userCol=COL_CUS, \n",
    "    itemCol=COL_GAME, \n",
    "    ratingCol=COL_RATING, \n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "model = als.fit(dfs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the trained model to predict ratings with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_pred = model.transform(dfs_test).drop(COL_RATING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the prediction results, the model performance can be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 265:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE score = 0.05680242215609236\n",
      "MAE score = 0.05511392340144523\n",
      "R2 score = 0.9805484556908253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "evaluations = SparkValidation(\n",
    "    dfs_test,\n",
    "    dfs_pred,\n",
    "    col_user=COL_CUS,\n",
    "    col_item=COL_GAME,\n",
    "    col_rating=COL_RATING,\n",
    "    col_prediction=COL_PREDICTION,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"RMSE score = {}\".format(evaluations.rmse()),\n",
    "    \"MAE score = {}\".format(evaluations.mae()),\n",
    "    \"R2 score = {}\".format(evaluations.rsquared()),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top k for all users (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_rec = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 299:=================================>                   (63 + 12) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+\n",
      "|customer_id|     recommendations|\n",
      "+-----------+--------------------+\n",
      "|    8450054|[{55104, 1.005364...|\n",
      "|    8561354|[{1000002, 7.3052...|\n",
      "|    8387754|[{1000004, 0.0269...|\n",
      "|    8385254|[{1000052, 0.0308...|\n",
      "|    8616454|[{1000004, 0.0720...|\n",
      "|    8580454|[{1000004, 0.0125...|\n",
      "|    8679454|[{55104, 0.186197...|\n",
      "|    8488454|[{1000004, 2.2326...|\n",
      "|    8509454|[{1000004, 0.0634...|\n",
      "|    8680154|[{1000025, 0.0828...|\n",
      "+-----------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dfs_rec.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top k for a selected set of users (items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = dfs_train.select(als.getUserCol()).distinct().limit(3)\n",
    "\n",
    "dfs_rec_subset = model.recommendForUserSubset(users, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|customer_id|recommendations                                                                                                                                                                                                                                       |\n",
      "+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|8450054    |[{55104, 1.0053643E-20}, {1000026, 8.001455E-21}, {57714, 6.961263E-21}, {30271, 4.707042E-21}, {1000004, 4.184424E-21}, {15064, 4.012089E-21}, {1000021, 3.6333666E-21}, {34204, 3.2639856E-21}, {10310, 3.041613E-21}, {42153, 3.0066153E-21}]      |\n",
      "|8561354    |[{1000002, 7.3052965E-17}, {39064, 6.6516776E-17}, {1000049, 5.265503E-17}, {1000004, 4.427845E-17}, {15064, 4.2428946E-17}, {1000021, 3.8423843E-17}, {10310, 3.216589E-17}, {42210, 2.927401E-17}, {1000001, 2.2044171E-17}, {51057, 1.8739067E-17}]|\n",
      "|8387754    |[{1000004, 0.026952133}, {15064, 0.02583594}, {1000021, 0.02339715}, {10310, 0.019586539}, {42210, 0.017412545}, {39064, 0.0128634}, {51057, 0.011372214}, {34201, 0.011218236}, {30494, 0.010898385}, {1000059, 0.010364862}]                        |\n",
      "+-----------+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_rec_subset.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Recommenders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
